{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam Tuning\n",
    "\n",
    "Now that we know which models are performing better, it's time to perform cross validation and tune hyperparameters.\n",
    "- Do a google search for hyperparameter ranges for each type of model.\n",
    "\n",
    "GridSearch/RandomSearch are a great methods for checking off both of these tasks.\n",
    "\n",
    "There is a fairly significant issue with this approach for this particular problem (described below). But in the interest of creating a basic functional pipeline, you can just use the default Sklearn methods for now.\n",
    "\n",
    "## Preventing Data Leakage in Tuning - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its highly recommended you complete it, if you have time!**\n",
    "\n",
    "BUT we have a problem - if we calculated a numerical value to encode city (such as the mean of sale prices in that city) on the training data, we can't cross validate \n",
    "- The rows in each validation fold were part of the original calculation of the mean for that city - that means we're leaking information!\n",
    "- While sklearn's built in functions are extremely useful, sometimes it is necessary to do things ourselves\n",
    "\n",
    "You need to create two functions to replicate what Gridsearch does under the hood. This is a challenging, real world data problem! To help you out, we've created some psuedocode and docstrings to get you started. \n",
    "\n",
    "**`custom_cross_validation()`**\n",
    "- Should take the training data, and divide it into multiple train/validation splits. \n",
    "- Look into `sklearn.model_selection.KFold` to accomplish this - the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) shows how to split a dataframe and loop through the indexes of your split data. \n",
    "- Within your function, you should compute the city means on the training folds just like you did in Notebook 1 - you may have to re-join the city column to do this - and then join these values to the validation fold\n",
    "\n",
    "This psuedocode may help you fill in the function:\n",
    "\n",
    "```python\n",
    "kfold = KFold() # fit sklearn k folds on X_train\n",
    "train_folds = []\n",
    "val_folds = []\n",
    "for training_index, val_index in kfold.split(X_train):\n",
    "    train_fold, val_fold = #.iloc loop variables on X_train\n",
    "\n",
    "    # recompute training city means like you did in notebook 1 \n",
    "    # merge to validation fold\n",
    "        \n",
    "    train_folds.append(train_fold)\n",
    "    val_folds.append(val_fold)\n",
    "\n",
    "    return train_folds, val_folds\n",
    "```\n",
    "\n",
    "\n",
    "**`hyperparameter_search()`**\n",
    "- Should take the validation and training splits from your previous function, along with your dictionary of hyperparameter values\n",
    "- For each set of hyperparameter values, fit your chosen model on each set of training folds, and take the average of your chosen scoring metric. [itertools.product()](https://docs.python.org/3/library/itertools.html) will be helpful for looping through all combinations of hyperparameter values\n",
    "- Your function should output the hyperparameter values corresponding the highest average score across all folds. Alternatively, it could also output a model object fit on the full training dataset with these parameters.\n",
    "\n",
    "\n",
    "This psuedocode may help you fill in the function:\n",
    "\n",
    "```python\n",
    "hyperparams = # Generate hyperparam options with itertools\n",
    "hyperparam-scores = []\n",
    "for hyperparam-combo in hyperparams:\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for folds in allmyfolds:\n",
    "        # score fold the fold with the model/ hyperparams\n",
    "        scores.append(score-fold)\n",
    "        \n",
    "    score = scores.mean()\n",
    "    hyperparam-scores.append(score)\n",
    "# After loop, find max of hyperparam-scores. Best params are at same index in `hyperparams` loop iteratble\n",
    "```\n",
    "\n",
    "Docstrings have been provided below to get you started. Once you're done developing your functions, you should move them to `functions_variables.py` to keep your notebook clean \n",
    "\n",
    "Bear in mind that these instructions are just one way to tackle this problem - the inputs and output formats don't need to be exactly as specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "\n",
    "import functions_variables as fv\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "set_config(display=\"diagram\")\n",
    "X = pd.DataFrame()\n",
    "source_folder_name = '../data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop your custom functions here\n",
    "\n",
    "def custom_cross_validation(training_data, n_splits =5):\n",
    "    '''creates n_splits sets of training and validation folds\n",
    "\n",
    "    Args:\n",
    "      training_data: the dataframe of features and target to be divided into folds\n",
    "      n_splits: the number of sets of folds to be created\n",
    "\n",
    "    Returns:\n",
    "      A tuple of lists, where the first index is a list of the training folds, \n",
    "      and the second the corresponding validation fold\n",
    "\n",
    "    Example:\n",
    "        >>> output = custom_cross_validation(train_df, n_splits = 10)\n",
    "        >>> output[0][0] # The first training fold\n",
    "        >>> output[1][0] # The first validation fold\n",
    "        >>> output[0][1] # The second training fold\n",
    "        >>> output[1][1] # The second validation fold... etc.\n",
    "    '''\n",
    "\n",
    "    return training_folds, validation_folds\n",
    "\n",
    "def hyperparameter_search(training_folds, validation_folds, param_grid):\n",
    "    '''outputs the best combination of hyperparameter settings in the param grid, \n",
    "    given the training and validation folds\n",
    "\n",
    "    Args:\n",
    "      training_folds: the list of training fold dataframes\n",
    "      validation_folds: the list of validation fold dataframes\n",
    "      param_grid: the dictionary of possible hyperparameter values for the chosen model\n",
    "\n",
    "    Returns:\n",
    "      A list of the best hyperparameter settings based on the chosen metric\n",
    "\n",
    "    Example:\n",
    "        >>> param_grid = {\n",
    "          'max_depth': [None, 10, 20, 30],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'max_features': ['sqrt', 'log2']} # for random forest\n",
    "        >>> hyperparameter_search(output[0], output[1], param_grid = param_grid) \n",
    "        # assuming 'ouput' is the output of custom_cross_validation()\n",
    "        [20, 5, 2, 'log2'] # hyperparams in order\n",
    "    '''\n",
    "\n",
    "    return hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tuning and cross validation here \n",
    "# using GridsearchCV/ RandomsearchCV (MVP)\n",
    "# or your custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that we save our models.  In the old days, one just simply pickled (serialized) the model.  Now, however, certain model types have their own save format.  If the model is from sklearn, it can be pickled, if it's xgboost, for example, the newest format to save it in is JSON, but it can also be pickled.  It's a good idea to stay with the most current methods. \n",
    "- you may want to create a new `models/` subdirectory in your repo to stay organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error saving model to:../data/models/best_model.pkl: name 'best_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# save your best model here\n",
    "filename = 'best_model.pkl'\n",
    "filepath = os.path.join('../data/models/', filename)\n",
    "try:\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "        print(f\"file saved to: {filepath}\")\n",
    "except Exception as e:\n",
    "    print(f\"error saving model to:{filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline (Stretch)\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its highly recommended you complete it if you have time!**\n",
    "\n",
    "Once you've identified which model works the best, implement a prediction pipeline to make sure that you haven't leaked any data, and that the model could be easily deployed if desired.\n",
    "- Your pipeline should load the data, process it, load your saved tuned model, and output a set of predictions\n",
    "- Assume that the new data is in the same JSON format as your original data - you can use your original data to check that the pipeline works correctly\n",
    "- Beware that a pipeline can only handle functions with fit and transform methods.\n",
    "- Classes can be used to get around this, but now sklearn has a wrapper for user defined functions.\n",
    "- You can develop your functions or classes in the notebook here, but once they are working, you should import them from `functions_variables.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(TransformerMixin):\n",
    "    def __init__(self, source_folder_name):\n",
    "        self.folder_name = source_folder_name\n",
    "\n",
    "    def fit(self, X=None, y=None):  \n",
    "        return self  \n",
    "\n",
    "    def transform(self, X=None): \n",
    "        data = fv.load_data(self.folder_name)  \n",
    "        return data\n",
    "\n",
    "class DataCleaner(TransformerMixin):\n",
    "    def __init__(self, num_type_to_drop):\n",
    "        self.to_drop = num_type_to_drop\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  \n",
    "        cleaned_data = fv.clean_data(X, self.to_drop)  \n",
    "        return cleaned_data\n",
    "    \n",
    "class Scalar_numeric(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.numeric_columns = None\n",
    "        self.scalar = StandardScalar()\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.numeric_columns = X.select_dtypes(include=['int']).columns + X.select_dtypes(include=['float']).columns\n",
    "        self.scalar.fit(X[self.numeric_columns])  \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X[self.numeric_columns].copy()\n",
    "        X = self.scalar.transform(X)\n",
    "        return X\n",
    "    \n",
    "class PCA_bool(TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=self.n_components)\n",
    "        self.bool_columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.bool_columns = X.select_dtypes(include=['bool']).columns\n",
    "        self.pca.fit(X[self.bool_columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,y=None):\n",
    "        X = X[self.bool_columns].copy()\n",
    "        X = self.pca.transform(X)\n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline here\n",
    "\n",
    "pipe_load_clean = Pipeline([\n",
    "    ('loader', DataLoader(source_folder_name)),\n",
    "    ('cleaner', DataCleaner())\n",
    "    \n",
    "])\n",
    "#scaling the numeric data\n",
    "numeric_pipe = Pipeline([\n",
    "    ('scaling', Scalar_numeric())\n",
    "])\n",
    "#scaling the boolean data\n",
    "bool_pipe = Pipeline([\n",
    "    ('pca', PCA_bool(n_components = 10))\n",
    "])\n",
    "\n",
    "union_pipe = FeatureUnion(transformer_list=[\n",
    "    ('numeric', numeric_pipe),\n",
    "    ('boolean', PCA_bool)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Json: .gitkeep\n",
      "Not a Json: license.txt\n",
      "Not a Json: models\n",
      "Not a Json: processed\n",
      "Not a Json: uscities.csv\n",
      "Geocoding attempt 1 of 4...\n",
      "Error geocoding Nashville, Tennessee: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Nashville%2C+Tennessee%2C+downtown&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Geocoding attempt 2 of 4...\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = pipe_load_clean.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines come from sklearn.  When a pipeline is pickled, all of the information in the pipeline is stored with it.  For example, if we were deploying a model, and we had fit a scaler on the training data, we would want the same, already fitted scaling object to transform the new data with.  This is all stored when the pipeline is pickled.\n",
    "- save your final pipeline in your `models/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_built</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>lot_sqft</th>\n",
       "      <th>sqft</th>\n",
       "      <th>baths</th>\n",
       "      <th>garage</th>\n",
       "      <th>stories</th>\n",
       "      <th>beds</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>property_lon</th>\n",
       "      <th>...</th>\n",
       "      <th>city_lat</th>\n",
       "      <th>city_lon</th>\n",
       "      <th>type_apartment</th>\n",
       "      <th>type_condo</th>\n",
       "      <th>type_land</th>\n",
       "      <th>type_mobile</th>\n",
       "      <th>type_multi_family</th>\n",
       "      <th>type_single_family</th>\n",
       "      <th>type_townhomes</th>\n",
       "      <th>type_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>129900</td>\n",
       "      <td>11761</td>\n",
       "      <td>1478</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36117</td>\n",
       "      <td>-86.178412</td>\n",
       "      <td>...</td>\n",
       "      <td>32.374725</td>\n",
       "      <td>-86.312465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945</td>\n",
       "      <td>88500</td>\n",
       "      <td>6534</td>\n",
       "      <td>1389</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>36107</td>\n",
       "      <td>-86.273286</td>\n",
       "      <td>...</td>\n",
       "      <td>32.374725</td>\n",
       "      <td>-86.312465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>145000</td>\n",
       "      <td>17424</td>\n",
       "      <td>2058</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36109</td>\n",
       "      <td>-86.221454</td>\n",
       "      <td>...</td>\n",
       "      <td>32.374725</td>\n",
       "      <td>-86.312465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955</td>\n",
       "      <td>65000</td>\n",
       "      <td>9712</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36107</td>\n",
       "      <td>-86.284387</td>\n",
       "      <td>...</td>\n",
       "      <td>32.374725</td>\n",
       "      <td>-86.312465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>169000</td>\n",
       "      <td>10890</td>\n",
       "      <td>1804</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36106</td>\n",
       "      <td>-86.232662</td>\n",
       "      <td>...</td>\n",
       "      <td>32.374725</td>\n",
       "      <td>-86.312465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1910</td>\n",
       "      <td>99000</td>\n",
       "      <td>4792</td>\n",
       "      <td>1214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25314</td>\n",
       "      <td>-81.644994</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356629</td>\n",
       "      <td>-81.644059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1860</td>\n",
       "      <td>29700</td>\n",
       "      <td>7841</td>\n",
       "      <td>988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25387</td>\n",
       "      <td>-81.661662</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356629</td>\n",
       "      <td>-81.644059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1860</td>\n",
       "      <td>162250</td>\n",
       "      <td>65340</td>\n",
       "      <td>1470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25314</td>\n",
       "      <td>-81.659885</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356629</td>\n",
       "      <td>-81.644059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1860</td>\n",
       "      <td>63800</td>\n",
       "      <td>17428</td>\n",
       "      <td>1526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25302</td>\n",
       "      <td>-81.644214</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356629</td>\n",
       "      <td>-81.644059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1950</td>\n",
       "      <td>115500</td>\n",
       "      <td>52272</td>\n",
       "      <td>3858</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25302</td>\n",
       "      <td>-81.640806</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356629</td>\n",
       "      <td>-81.644059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_built  sold_price  lot_sqft  sqft  baths  garage  stories  beds  \\\n",
       "0           1998      129900     11761  1478      2       2        1     3   \n",
       "1           1945       88500      6534  1389      2       1        2     4   \n",
       "2           1969      145000     17424  2058      2       0        1     3   \n",
       "3           1955       65000      9712  1432      2       0        1     3   \n",
       "4           1984      169000     10890  1804      2       0        1     3   \n",
       "...          ...         ...       ...   ...    ...     ...      ...   ...   \n",
       "1468        1910       99000      4792  1214      1       1        2     3   \n",
       "1469        1860       29700      7841   988      1       0        1     3   \n",
       "1470        1860      162250     65340  1470      1       0        1     3   \n",
       "1471        1860       63800     17428  1526      0       0        1     0   \n",
       "1472        1950      115500     52272  3858      2       0        1     3   \n",
       "\n",
       "      postal_code  property_lon  ...   city_lat   city_lon  type_apartment  \\\n",
       "0           36117    -86.178412  ...  32.374725 -86.312465           False   \n",
       "1           36107    -86.273286  ...  32.374725 -86.312465           False   \n",
       "2           36109    -86.221454  ...  32.374725 -86.312465           False   \n",
       "3           36107    -86.284387  ...  32.374725 -86.312465           False   \n",
       "4           36106    -86.232662  ...  32.374725 -86.312465           False   \n",
       "...           ...           ...  ...        ...        ...             ...   \n",
       "1468        25314    -81.644994  ...  38.356629 -81.644059           False   \n",
       "1469        25387    -81.661662  ...  38.356629 -81.644059           False   \n",
       "1470        25314    -81.659885  ...  38.356629 -81.644059           False   \n",
       "1471        25302    -81.644214  ...  38.356629 -81.644059           False   \n",
       "1472        25302    -81.640806  ...  38.356629 -81.644059           False   \n",
       "\n",
       "      type_condo  type_land  type_mobile  type_multi_family  \\\n",
       "0          False      False        False              False   \n",
       "1          False      False        False              False   \n",
       "2          False      False        False              False   \n",
       "3          False      False        False              False   \n",
       "4          False      False        False              False   \n",
       "...          ...        ...          ...                ...   \n",
       "1468       False      False        False              False   \n",
       "1469       False      False        False              False   \n",
       "1470       False      False        False              False   \n",
       "1471       False      False        False              False   \n",
       "1472       False      False        False              False   \n",
       "\n",
       "      type_single_family  type_townhomes  type_nan  \n",
       "0                   True           False     False  \n",
       "1                   True           False     False  \n",
       "2                   True           False     False  \n",
       "3                   True           False     False  \n",
       "4                   True           False     False  \n",
       "...                  ...             ...       ...  \n",
       "1468                True           False     False  \n",
       "1469                True           False     False  \n",
       "1470                True           False     False  \n",
       "1471                True           False     False  \n",
       "1472                True           False     False  \n",
       "\n",
       "[1473 rows x 106 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your pipeline here\n",
    "cleaned_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
